#!/usr/bin/env python3
"""
Ù…ØªØ¹Ø±Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
Advanced Pattern Recognizer
"""

import torch
import transformers
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import re
from typing import Dict, List, Any
import logging

class AdvancedPatternRecognizer:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.setup_deep_learning_models()
    
    def setup_deep_learning_models(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚"""
        self.logger.info("ğŸ§  ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚...")
        
        try:
            # Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
            self.sentiment_analyzer = transformers.pipeline(
                "sentiment-analysis",
                model="cardiffnlp/twitter-roberta-base-sentiment-latest"
            )
            
            # Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ù…Ø§Ø©
            self.ner_analyzer = transformers.pipeline(
                "ner",
                model="dslim/bert-base-NER",
                aggregation_strategy="simple"
            )
            
            self.logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
            
        except Exception as e:
            self.logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {e}")
    
    async def analyze_text_patterns(self, text_data: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù†Øµ"""
        analysis_results = {}
        
        try:
            # ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
            analyses = [
                self.semantic_analysis(text_data),
                self.entity_recognition(text_data),
                self.sentiment_analysis(text_data),
                self.behavioral_pattern_analysis(text_data)
            ]
            
            # ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
            for analysis in analyses:
                analysis_results.update(analysis)
            
            self.logger.info("âœ… Ø§ÙƒØªÙ…Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·")
            
        except Exception as e:
            self.logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {e}")
            
        return analysis_results
    
    def semantic_analysis(self, text: str) -> Dict[str, Any]:
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ"""
        semantic_insights = {}
        
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ
            if len(text) > 512:
                text = text[:512]  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
            
            sentiment_result = self.sentiment_analyzer(text)
            semantic_insights['sentiment'] = sentiment_result[0]
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹Ø§Øª
            topics = self.extract_topics(text)
            semantic_insights['topics'] = topics
            
        except Exception as e:
            self.logger.warning(f"Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ ÙØ´Ù„: {e}")
            
        return semantic_insights
    
    def entity_recognition(self, text: str) -> Dict[str, Any]:
        """Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª"""
        entities_data = {}
        
        try:
            # Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ù…Ø§Ø©
            ner_results = self.ner_analyzer(text)
            
            entities_data['named_entities'] = {
                'persons': [ent for ent in ner_results if ent['entity_group'] == 'PER'],
                'organizations': [ent for ent in ner_results if ent['entity_group'] == 'ORG'],
                'locations': [ent for ent in ner_results if ent['entity_group'] == 'LOC'],
                'misc': [ent for ent in ner_results if ent['entity_group'] == 'MISC']
            }
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù‡Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„
            entities_data['potential_contacts'] = self.extract_contacts_from_entities(ner_results)
            
        except Exception as e:
            self.logger.warning(f"Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª ÙØ´Ù„: {e}")
            
        return entities_data
    
    def extract_contacts_from_entities(self, entities: List[Dict]) -> Dict[str, List[str]]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù‡Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ù† Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª"""
        contacts = {
            'emails': [],
            'phones': [],
            'social_media': []
        }
        
        try:
            for entity in entities:
                entity_word = entity['word']
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª
                if re.match(r'^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}$', entity_word):
                    contacts['emails'].append(entity_word)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆØ§ØªÙ
                elif re.match(r'^\+\d{1,3}[-.\s]?\d{1,4}[-.\s]?\d{1,4}[-.\s]?\d{1,9}$', entity_word):
                    contacts['phones'].append(entity_word)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„
                elif any(platform in entity_word.lower() for platform in ['facebook', 'twitter', 'instagram', 'linkedin']):
                    contacts['social_media'].append(entity_word)
                    
        except Exception as e:
            self.logger.warning(f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¬Ù‡Ø§Øª Ù…Ù† Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª ÙØ´Ù„: {e}")
            
        return contacts
    
    def extract_topics(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ù…Ù† Ø§Ù„Ù†Øµ"""
        topics = []
        
        try:
            # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø´Ø§Ø¦Ø¹Ø©
            keywords = {
                'technology': ['computer', 'software', 'programming', 'tech'],
                'business': ['company', 'work', 'job', 'business'],
                'education': ['school', 'university', 'study', 'learn'],
                'personal': ['family', 'friend', 'home', 'life']
            }
            
            text_lower = text.lower()
            for topic, words in keywords.items():
                if any(word in text_lower for word in words):
                    topics.append(topic)
            
        except Exception as e:
            self.logger.warning(f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹Ø§Øª ÙØ´Ù„: {e}")
            
        return topics
